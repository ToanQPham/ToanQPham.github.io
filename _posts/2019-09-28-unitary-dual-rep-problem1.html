---
layout: post
title: "Problem 1 - Unitary representation of dual space"
categories: 
- Representation theory
tag: 
- Representation theory
- Lie algebra
---

 <div style= " background: #ffffff; border-left: 5px solid grey; margin: 10px 0px 10px 0px; padding-left: 10px; font-size:13px "><b>Problem 1.</b>  Let $V$ finite-dimensional vector space over ${\mathbb C}$ admitting symmetric nondegenerate seaqui-linear form $(,)$: 

<ol> <li> symmetry: $(v,w)=\overline{(w,v)}$. <li> (sesqui-)linearity: $(v,\alpha w+\beta u)=\alpha(v,w)+\beta(v,u)$. <li> non-degeneracy: $(v,w)=0 \forall w\in W\implies v=0$. 
</ol>

 for all $v,u,w\in V; \alpha,\beta\in {\mathbb C}$ where the overbar denotes the complex conjugation. Suppose $\{v_i:1 \le i \le n\}$ basis of $V$ over ${\mathbb C}$ and let $g$ denotes the matrix $g_{i,j}=(v_i,v_j)$. 

<ol> <li> Show that the matrix $g$ is non-singular. <li> Let $v^i=\sum_j\overline{g^{ij}}v_j$ where $g^{ij}=(g^{-1})_{i,j}$. Show $\{v^i:1 \le i \le n\}$ basis of $V$ which is dual of $\{v_i\}$ in the sense that $(v^i,v_j)=\delta_{i,j}$ <li> Deduce that $g^{ij}=(v^jv^i)$. 
</ol>

 
</div>

<p>


<p>
 (i) Since if $(v,w)=0$ then $(w,v)=\overline{(v,w)}=0$ so the non-degeneracy condition can be stated as: if $(v,w)=0$ for all $v\in V$ then $w=0$. 
<p>
To show $g$ is non-singular, it suffices to show that its rows are linearly independent. Indeed, denote $i$-th row of $g$ to be $r_i$ then $r_i=((v_i,v_1),(v_iv_2),\ldots, (v_i,v_n))$. If $\sum_{i=1}^n \alpha_ir_i=0$ for some $\alpha_i\in {\mathbb C}$ then this implies $(\alpha,v_j)= \left( \sum_{i=1}^n \alpha_iv_i,v_j\right)=0$ for all $1 \le j \le n$. Since $\{v_j:1\le j\le n\}$ basis of $V$ so $\left(\alpha,v\right)=0$ for all $v\in V$. This implies $\alpha=0$ or $\sum_{i=1}^n \alpha_iv_i=0$. Since $\{v_i:1\le i \le n\}$ basis of $V$ so $\alpha_i=0$ for all $1 \le i \le n$, implying that the rows of $g$ are linearly independent, as desired. 
<p>
(ii) Consider the $n\times n$ matrix $A$ where $A_{i,j}=\overline{g^{ji}}$ then $A$ is the conjugate transpose of $g^{-1}$, meaning $A$ is invertible. One can view $A$ as matrix whose columns are coefficients of $v^i$ in basis $\{v_i:1\le i\le n\}$. Since $A$ is invertible, there exists column vector $\mathbf{x}=(\alpha_i)_{1\le i\le n}$ such that $Ax=\begin{pmatrix}1 \\ 0 \\ \vdots \\ 0 \end{pmatrix}$. This means $\sum_{i=1}^n \alpha_i v^i=v_1$. Hence, $v_1$ in span of $\{v^i:1 \le i \le n\}$. Similarly, one can show all $v_i$'s are in the span of $\{v^j:1 \le j \le n\}$, implying $\{v^j:1 \le j \le n\}$ is a spanning set, hence a basis, of $V$. 
<p>
We have <p align=center>$\displaystyle  \begin{aligned}  (v^i,v_j) & = \left( \sum_{k=1}^n \overline{g^{-1}_{i,k}}v_k, v_j\right), & \\ & = \overline{\left( v_j, \sum_{k=1}^n \overline{g^{-1}_{i,k}}v_k\right)} & \text{(symmetry)}, \\ & = \sum_{k=1}^n g^{-1}_{i,k}\overline{(v_j,v_k)} & \text{(linearity)}, \\ & = \sum_{k=1}^n g^{-1}_{i,k} (v_k,v_j), & \text{(symmetry)} \\ & = \sum_{k=1}^n g^{-1}_{i,k} g_{k,j}, & \\ & = (gg^{-1})_{i,j}=(I_{n\times n})_{i,j}, & \\ & = \delta_{i,j}. & \end{aligned} $</p>
 (iii) We have <p align=center>$\displaystyle  \begin{aligned}  (v^j,v^i) & = \left( v^j, \sum_{k=1}^n \overline{g^{i,k}}v_k \right), \\ & = \sum_{k=1}^n \overline{g^{i,k}}(v^j,v_k), \\ & = \sum_{k=1}^n \overline{g^{i,k}}\delta_{j,k}, \\ & = \overline{g^{i,j}}. \end{aligned} $</p>
 This follows from symmetry property that $g^{i,j}= (v^i,v^j)$. 
<p>
 
 <div style= " background: #ffffff; border-left: 5px solid grey; margin: 10px 0px 10px 0px; padding-left: 10px; font-size:13px "><b>Definition 2.</b>  Let $L$ the Lie algebra over ${\mathbb C}$. We call anti-linear map $\star: L\rightarrow L$ a <var>star operation</var> on $L$ if it satisfies the following: 

<ol> <li> anti-linearity: $(\alpha a+\beta b)^*=\overline{\alpha} a^*+\overline{\beta}b^*$ <li> $a^{**}=a$. <li> $[a,b]^*=[b^*,a^*]$. 
</ol>

 for all $a,b\in L$ and $\alpha,\beta\in {\mathbb C}$. 
</div>

<p>


<p>
Let $L$ complex Lie algebra with a star operation $*$. We call an $L$ module $V$ <var>unitary</var> if it can be equipped with an inner product $(,)$ which respects the star operation in the sense that $(av,w)=(v,a^*w)$ for all $a\in L;v,w\in V$.
<p>
We show that if $V$ is unitary then so is $V^*$.
<p>
 Recall $V^*$ is an $L$-module with action $(x.f)(v)=-f(x.v)$ for $x\in L,f\in V^*, v\in V$. To show $V^*$ is unitary, we want to define inner product on $V^*$ that respects the star operation. For $v_1,\ldots, v_n$ basis of $V$, denote $v^1,v^2, \ldots, v^n$ another basis of $V$ as defined in the lecture notes such that $(v^i,v_j)=\delta_{i,j}$.
<p>
Let $v_i^*$'s be the dual basis of $V^*$ corresponding to $v_i$ and $(v^i)^*$'s be dual basis of $V^*$ corresponding to $v^j$. We define the the inner product $\langle ,\rangle$ on $V^*$ to be <a name="definner_prod_dual_rep"><p align=center>$\displaystyle   \langle (v^i)^*,v_j^*\rangle = \delta_{i,j} \ \ \ \ \ (1)$</p>
</a> and extend linearly. 
<p>
Before showing that this is an inner product on $V^*$ that respects the star operation, we recall that since $(v_i,v^j)=\delta_{i,j}$ so every $v\in V$ can be written as <a name="eqn1"><p align=center>$\displaystyle   v=\sum_i (v,v_i)v^i=\sum_i(v,v^i)v_i \ \ \ \ \ (2)$</p>
</a>
<p>
First we show that this is indeed an inner product on $V^*$. (Sesqui-)linearity follows from the way we define the inner product (i.e. we extend it linearly from the basis of $V^*$). To show symmetry holds, we need to show $\langle v_j^*, (v^i)^*\rangle =\delta_{i,j}$. First, we will try to write $v_j^*$ in terms of $(v^i)^*$. We have $v^j=\sum_{k}\overline{g_{jk}^{-1}}v_k$ from Q2(ii) so $(v_i)^*(v^j)=\overline{g_{ji}^{-1}}$. This follows <p align=center>$\displaystyle (v_i)^*= \sum_j \overline{g_{ji}^{-1}}(v^j)^*.$</p>
 Similarly, since $v_j=\sum_k (v_j,v_k)v^k$ so $(v^i)^*(v_j)=(v_j,v_i)=g_{ji}$ so $(v^i)^*= \sum_j g_{ji}(v_j)^*$. Therefore, <p align=center>$\displaystyle  \langle v_j^*, (v^i)^*\rangle = \left\langle \sum_k \overline{g_{kj}^{-1}}(v^k)^*, \sum_{\ell} g_{\ell i}(v_{\ell})^*\right\rangle =\sum_{k,\ell} g_{kj}^{-1}g_{\ell,i} \langle (v^k)^*, (v_\ell)^*\rangle = \sum_{k=1}^n g_{kj}^{-1}g_{ki}= \sum_{k=1}^n g_{kj}^{-1}\overline{g_{ik}} =(g^{-1}g^{\dagger})_{ij}.$</p>
 Recall $g$ is a matrix with $g_{ij}=(v_i,v_j)$ so $g_{ij}=\overline{g_{ji}}$ so $g=g^{\dagger}$. Since $g$ invertible so $gg^{-1}=I_{n}$. This follows $g^{\dagger}g^{-1}=I_{n\times n}$, proving that symmetry holds for $\langle,\rangle$.
<p>
To show $\langle ,\rangle$ is positive definite, for any $f\in V^*$ then $f=\sum_i \alpha_i (v^i)^*$. This follows $f=\sum_i\alpha_i \sum_j g_{ji}(v_j)^* =\sum_j (v_j)^* \sum_i \alpha_ig_{ji}$. Thus, <p align=center>$\displaystyle \langle f,f \rangle = \left \langle \sum_i \alpha_i (v^i)^*, \sum_j (v_j)^* \sum_k \alpha_kg_{jk} \right \rangle = \sum_i \overline{\alpha_i}\sum_k \alpha_kg_{ik} = \left( \sum_i \alpha_iv_i,\sum_i\alpha_iv_j \right)\ge 0. $</p>
 Equality holds iff $\sum_i \alpha_iv_i=0$ iff $\alpha_i=0$ for all $1 \le i \le n$ iff $f=0$, as desired. 
<p>
Finally, we show $\langle ,\rangle$ respects the star operation, i.e. we want $\langle a(v^i)^*, v_j^*\rangle = \langle (v^i)^*, a^*v_j^*\rangle$. We have <p align=center>$\displaystyle  a(v^i)^*(v^j)=-(v^i)^*(av^j) =-(v^i)^* \left( \sum_k (av^j,v_k)v^k \right) = -(av^j,v_i).$</p>
 Hence, $a(v^i)^*= -\sum_k (av^k,v_i)(v^k)^*$. This follows <a name="eq2"><p align=center>$\displaystyle   LHS=\langle a(v^i)^*,v_j^*\rangle = \left\langle -\sum_k (av^k,v_i)(v^k)^*, v_j^* \right\rangle= -\overline{(av^j,v_i)} =- (v_i,av^j). \ \ \ \ \ (3)$</p>
</a> Similarly, since <p align=center>$\displaystyle  a^*(v_j)^*(v_i) = -(v_j)^*(a^*v_i) =-v_j^*\left( \sum_k (a^*v_i,v^k)v_k \right) =-(a^*v_i,v^j).$</p>
 Hence, $a^*(v_j)^* = - \sum_k (a^*v_k,v^j)(v_k)^*$. Therefore, <a name="eq3"><p align=center>$\displaystyle   RHS= \left\langle (v^i)^*, - \sum_k (a^*v_k,v^j)(v_k)^* \right \rangle = -(a^*v_i,v^j). \ \ \ \ \ (4)$</p>
</a> From <a href="#eq2">(3)</a> and <a href="#eq3">(4)</a> and the fact $(,)$ on $V$ is unitary so we are done. 
<p>
 